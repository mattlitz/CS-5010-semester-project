{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd055256d91f5f4179392f32e5ade284e0771d80789c6f35f717a86b952c71b8fa9",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#raw data\n",
    "df=pd.read_csv(r'data/CSPDS.csv')\n",
    "\n",
    "#df['County'] = df['Region Name'].str.split(' ')[0]\n",
    "\n",
    "#code for calculating chloropleth\n",
    "zip = geopandas.read_file('shapefiles/cb_2018_us_zcta510_500k.shp')\n",
    "counties =geopandas.read_file('shapefiles/cb_2018_us_county_20m.shp')\n",
    "#csa = geopandas.read_file('shapefiles/cb_2018_us_csa_20m.shp')\n",
    "states = geopandas.read_file('shapefiles/cb_2018_us_state_20m.shp')\n",
    "#print(csa.head())\n",
    "\n",
    "zip = zip.to_crs(\"EPSG:3395\")\n",
    "counties=counties.to_crs(\"EPSG:3395\")\n",
    "#csa = csa.to_crs(\"EPSG:3395\")\n",
    "states = states.to_crs(\"EPSG:3395\")\n",
    "        \n",
    "\n",
    "#Alaska and Hawaii excluded due to lack of CSA\n",
    "states=states[states['NAME'] != 'Alaska']\n",
    "states=states[states['NAME'] != 'Hawaii']\n",
    "states=states[states['NAME'] != 'Puerto Rico']\n",
    "\n",
    "counties=counties[counties['STATEFP'] != '02']\n",
    "counties=counties[counties['STATEFP'] != '15']\n",
    "counties=counties[counties['STATEFP'] != '72']\n",
    "\n",
    "us_boundary_map = states.boundary.plot(figsize=(18, 12),color=\"Black\", linewidth=.1)\n",
    "#.plot(figsize=(18, 12),color=\"Black\", linewidth=.1)\n",
    "counties.plot(ax=us_boundary_map, cmap='magma')\n",
    "counties\n",
    "#zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from fredapi import Fred\n",
    "fred = Fred(api_key='d7f545fe7858da4279909dd26a7b28cc')\n",
    "data = fred.get_series('DAAA')\n",
    "data.plot()\n",
    "data\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(type(data))\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#convert time\n",
    "\n",
    "year= '2020'\n",
    "\n",
    "year_dt = datetime.strptime(year, '%Y')\n",
    "\n",
    "print(str(year_dt.date()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "\n",
    "\n",
    "county_map=r'shapefiles/cb_2018_us_county_20m.geojson'\n",
    "\n",
    "        \n",
    "\n",
    "#coordinate = (37.8199286, -122.4782551)\n",
    "m = folium.Map(\n",
    "    tiles='CartoDB positron',\n",
    "    location=[48, -102],\n",
    "    zoom_start=3,            \n",
    ")\n",
    "\n",
    "folium.GeoJson(county_map, name=\"geojson\").add_to(m)\n",
    "\n",
    "#folium.GeoJson(open(county_map).read()).add_to(m)\n",
    "\n",
    "# folium.TopoJson(\n",
    "#    open(county_map)).add_to(m)\n",
    "\n",
    "#folium.Choropleth(open(county_map)).add_to(m)\n",
    "\n",
    "#folium.Choropleth(geo_data=county_map).add_to(m)\n",
    "\n",
    "#  folium.Choropleth(\n",
    "    #  geo_data=county_map,\n",
    "    # name=\"choropleth\",\n",
    "    # data=state_data,\n",
    "    # columns=[\"State\", \"Unemployment\"],\n",
    "    # key_on=\"feature.id\",\n",
    "    #fill_color=\"YlGn\",\n",
    "    #fill_opacity=0.7,\n",
    "    # line_opacity=0.2,\n",
    "    #legend_name=\"Median Housing Price Correlations\",\n",
    "# ).add_to(m)\n",
    "\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca\n",
    "import json\n",
    "import requests\n",
    "\n",
    "county_data = r'shapefiles/us_county_data.csv'\n",
    "county_geo = r'shapefiles/us_counties_20m_topo.json'\n",
    "\n",
    "\n",
    "df = pd.read_csv(county_data, na_values=[\" \"])\n",
    "\n",
    "colorscale = branca.colormap.linear.YlOrRd_09.scale(0, 50e3)\n",
    "employed_series = df.set_index(\"FIPS_Code\")[\"Employed_2011\"]\n",
    "\n",
    "\n",
    "def style_function(feature):\n",
    "    employed = employed_series.get(int(feature[\"id\"][-5:]), None)\n",
    "    return {\n",
    "        \"fillOpacity\": 0.5,\n",
    "        \"weight\": 0,\n",
    "        \"fillColor\": \"#black\" if employed is None else colorscale(employed),\n",
    "    }\n",
    "\n",
    "\n",
    "m = folium.Map(location=[48, -102], tiles=\"cartodbpositron\", zoom_start=3)\n",
    "\n",
    "folium.TopoJson(\n",
    "    open(county_geo),\n",
    "    \"objects.us_counties_20m\",\n",
    "    style_function=style_function,\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import io\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "county_data = r'shapefiles/us_county_data.csv'\n",
    "#county_geo = r'shapefiles/gz_2010_us_050_00_20m.json'\n",
    "county_geo = r'shapefiles/cb_2018_us_county_20m.geojson'\n",
    "\n",
    "\n",
    "df = pd.read_csv(county_data, na_values=[\" \"])\n",
    "print(df.dtypes)\n",
    "df[\"FIPS_Code\"] = df[\"FIPS_Code\"].astype(str)\n",
    "print(df.dtypes)\n",
    "\n",
    "m = folium.Map(location=[48, -102], tiles=\"cartodbpositron\", zoom_start=3)\n",
    "\n",
    "#folium.GeoJson(county_geo, name=\"geojson\").add_to(m)\n",
    "\n",
    "bins = list(df[\"Unemployment_rate_2011\"].quantile([0, 0.25, 0.5, 0.75, 1]))\n",
    "\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data= county_geo,\n",
    "    name=\"choropleth\",\n",
    "    data=df,\n",
    "    columns=[\"FIPS_Code\",\"Unemployment_rate_2011\"],\n",
    "    key_on=\"properties.GEOID\",\n",
    "    fill_color=\"YlGnBu\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    legend_name=\"Unemployment Rate (%)\",\n",
    "    bins=bins,\n",
    "    reset=True,\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data\"\n",
    ")\n",
    "state_geo = f\"{url}/us-states.json\"\n",
    "state_unemployment = f\"{url}/US_Unemployment_Oct2012.csv\"\n",
    "state_data = pd.read_csv(state_unemployment)\n",
    "\n",
    "m = folium.Map(location=[48, -102], zoom_start=3)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=state_geo,\n",
    "    name=\"choropleth\",\n",
    "    data=state_data,\n",
    "    columns=[\"State\", \"Unemployment\"],\n",
    "    key_on=\"feature.id\",\n",
    "    fill_color=\"YlGn\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Unemployment Rate (%)\",\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Import FRED data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            CASE-SHILLER      CPI         M2  UNRATE      EFFR      10YR  \\\n",
       "2012-01-31       136.602  227.842   9770.560     8.3  0.084500  1.966500   \n",
       "2012-02-29       136.526  228.329   9782.900     8.3  0.105000  1.967500   \n",
       "2012-03-31       137.902  228.807   9893.650     8.2  0.127273  2.172727   \n",
       "2012-04-30       139.156  229.187   9949.200     8.2  0.145238  2.052857   \n",
       "2012-05-31       140.158  228.713   9884.900     8.2  0.156364  1.803182   \n",
       "...                  ...      ...        ...     ...       ...       ...   \n",
       "2017-09-30       193.806  246.551  13704.075     4.2  1.155000  2.202000   \n",
       "2017-10-31       194.772  246.657  13749.120     4.1  1.155714  2.360000   \n",
       "2017-11-30       195.856  247.378  13822.975     4.2  1.155714  2.353333   \n",
       "2017-12-31       197.035  247.736  13933.500     4.1  1.298500  2.402500   \n",
       "2018-01-31       198.173  248.721  13889.580     4.0  1.416190  2.583810   \n",
       "\n",
       "            30YR_MORT  PERS_SAV     WTI_OIL   BUSLOANS  CORP_BOND  Adj Close  \n",
       "2012-01-31     3.9150       8.0  100.273500  1321.3113   3.850000   0.072220  \n",
       "2012-02-29     3.8900       8.0  102.204000  1344.4480   3.846500   0.096855  \n",
       "2012-03-31     3.9540       8.5  106.157727  1351.1006   3.987273   0.105987  \n",
       "2012-04-30     3.9100       8.7  103.321000  1368.4854   3.961429   0.096986  \n",
       "2012-05-31     3.7980       8.8   94.654545  1378.9337   3.801364   0.084533  \n",
       "...               ...       ...         ...        ...        ...        ...  \n",
       "2017-09-30     3.8050       7.3   49.822000  2101.3416   3.629500   0.022200  \n",
       "2017-10-31     3.8950       7.4   51.577727  2109.9100   3.597727   0.035182  \n",
       "2017-11-30     3.9220       7.0   56.638571  2105.4603   3.574000   0.036429  \n",
       "2017-12-31     3.9500       6.6   57.881500  2105.8431   3.507500   0.039250  \n",
       "2018-01-31     4.0325       7.5   63.698571  2110.7760   3.547619   0.051250  \n",
       "\n",
       "[73 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CASE-SHILLER</th>\n      <th>CPI</th>\n      <th>M2</th>\n      <th>UNRATE</th>\n      <th>EFFR</th>\n      <th>10YR</th>\n      <th>30YR_MORT</th>\n      <th>PERS_SAV</th>\n      <th>WTI_OIL</th>\n      <th>BUSLOANS</th>\n      <th>CORP_BOND</th>\n      <th>Adj Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2012-01-31</th>\n      <td>136.602</td>\n      <td>227.842</td>\n      <td>9770.560</td>\n      <td>8.3</td>\n      <td>0.084500</td>\n      <td>1.966500</td>\n      <td>3.9150</td>\n      <td>8.0</td>\n      <td>100.273500</td>\n      <td>1321.3113</td>\n      <td>3.850000</td>\n      <td>0.072220</td>\n    </tr>\n    <tr>\n      <th>2012-02-29</th>\n      <td>136.526</td>\n      <td>228.329</td>\n      <td>9782.900</td>\n      <td>8.3</td>\n      <td>0.105000</td>\n      <td>1.967500</td>\n      <td>3.8900</td>\n      <td>8.0</td>\n      <td>102.204000</td>\n      <td>1344.4480</td>\n      <td>3.846500</td>\n      <td>0.096855</td>\n    </tr>\n    <tr>\n      <th>2012-03-31</th>\n      <td>137.902</td>\n      <td>228.807</td>\n      <td>9893.650</td>\n      <td>8.2</td>\n      <td>0.127273</td>\n      <td>2.172727</td>\n      <td>3.9540</td>\n      <td>8.5</td>\n      <td>106.157727</td>\n      <td>1351.1006</td>\n      <td>3.987273</td>\n      <td>0.105987</td>\n    </tr>\n    <tr>\n      <th>2012-04-30</th>\n      <td>139.156</td>\n      <td>229.187</td>\n      <td>9949.200</td>\n      <td>8.2</td>\n      <td>0.145238</td>\n      <td>2.052857</td>\n      <td>3.9100</td>\n      <td>8.7</td>\n      <td>103.321000</td>\n      <td>1368.4854</td>\n      <td>3.961429</td>\n      <td>0.096986</td>\n    </tr>\n    <tr>\n      <th>2012-05-31</th>\n      <td>140.158</td>\n      <td>228.713</td>\n      <td>9884.900</td>\n      <td>8.2</td>\n      <td>0.156364</td>\n      <td>1.803182</td>\n      <td>3.7980</td>\n      <td>8.8</td>\n      <td>94.654545</td>\n      <td>1378.9337</td>\n      <td>3.801364</td>\n      <td>0.084533</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2017-09-30</th>\n      <td>193.806</td>\n      <td>246.551</td>\n      <td>13704.075</td>\n      <td>4.2</td>\n      <td>1.155000</td>\n      <td>2.202000</td>\n      <td>3.8050</td>\n      <td>7.3</td>\n      <td>49.822000</td>\n      <td>2101.3416</td>\n      <td>3.629500</td>\n      <td>0.022200</td>\n    </tr>\n    <tr>\n      <th>2017-10-31</th>\n      <td>194.772</td>\n      <td>246.657</td>\n      <td>13749.120</td>\n      <td>4.1</td>\n      <td>1.155714</td>\n      <td>2.360000</td>\n      <td>3.8950</td>\n      <td>7.4</td>\n      <td>51.577727</td>\n      <td>2109.9100</td>\n      <td>3.597727</td>\n      <td>0.035182</td>\n    </tr>\n    <tr>\n      <th>2017-11-30</th>\n      <td>195.856</td>\n      <td>247.378</td>\n      <td>13822.975</td>\n      <td>4.2</td>\n      <td>1.155714</td>\n      <td>2.353333</td>\n      <td>3.9220</td>\n      <td>7.0</td>\n      <td>56.638571</td>\n      <td>2105.4603</td>\n      <td>3.574000</td>\n      <td>0.036429</td>\n    </tr>\n    <tr>\n      <th>2017-12-31</th>\n      <td>197.035</td>\n      <td>247.736</td>\n      <td>13933.500</td>\n      <td>4.1</td>\n      <td>1.298500</td>\n      <td>2.402500</td>\n      <td>3.9500</td>\n      <td>6.6</td>\n      <td>57.881500</td>\n      <td>2105.8431</td>\n      <td>3.507500</td>\n      <td>0.039250</td>\n    </tr>\n    <tr>\n      <th>2018-01-31</th>\n      <td>198.173</td>\n      <td>248.721</td>\n      <td>13889.580</td>\n      <td>4.0</td>\n      <td>1.416190</td>\n      <td>2.583810</td>\n      <td>4.0325</td>\n      <td>7.5</td>\n      <td>63.698571</td>\n      <td>2110.7760</td>\n      <td>3.547619</td>\n      <td>0.051250</td>\n    </tr>\n  </tbody>\n</table>\n<p>73 rows × 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "from pandas_datareader import data\n",
    "\n",
    "fred = Fred(api_key='d7f545fe7858da4279909dd26a7b28cc')\n",
    "\n",
    "df = {}\n",
    "\n",
    "df['CASE-SHILLER'] = fred.get_series('CSUSHPISA', observation_start='1/31/1996') #S&P/Case-Shiller U.S. National Home Price Index\n",
    "df['CPI'] = fred.get_series('CPIAUCSL', observation_start='1/31/1996') #Consumer Price Index for All Urban Consumers: All Items in U.S. City Average\n",
    "df['M2'] = fred.get_series('WM2NS', observation_start='1/31/1996')#M2 Money Stock\n",
    "df['UNRATE'] = fred.get_series('UNRATE', observation_start='1/31/1996')#M2 Money Stock\n",
    "df['EFFR'] = fred.get_series('EFFR', observation_start='1/31/1996')#Effective Federal Funds Rate\n",
    "df['10YR'] = fred.get_series('DGS10', observation_start='1/31/1996') #10-Year Treasury Constant Maturity Rate\n",
    "df['30YR_MORT'] = fred.get_series('MORTGAGE30US', observation_start='1/31/1996') #30-Year Fixed Rate Mortgage Average in the United States\n",
    "df['PERS_SAV'] = fred.get_series('PSAVERT', observation_start='1/31/1996') #Personal Saving Rate\n",
    "df['WTI_OIL'] = fred.get_series('DCOILWTICO', observation_start='1/31/1996') #Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma\n",
    "df['BUSLOANS'] = fred.get_series('BUSLOANS', observation_start='1/31/1996')#Commercial and Industrial Loans, All Commercial Banks\n",
    "df['CORP_BOND'] = fred.get_series('DAAA', observation_start='1/31/1996')#Moody's Seasoned Aaa Corporate Bond Yield\n",
    "df = pd.DataFrame(df).resample('M').mean()\n",
    "#df=df.dropna()\n",
    "\n",
    "#import SPY data \n",
    "start_date = pd.to_datetime('2012-01-31')\n",
    "end_date = pd.to_datetime('2021-04-30')\n",
    "\n",
    "# User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "panel_data = data.DataReader('SPX','yahoo', start_date, end_date)\n",
    "spy=panel_data['Adj Close'].to_frame().resample('M').mean()\n",
    "\n",
    "#add_df = pd.concat([df, spy])\n",
    "fred_df = df.merge(spy, left_index=True, right_index=True)\n",
    "\n",
    "del df, panel_data, spy\n",
    "\n",
    "fred_df\n",
    "\n",
    "#df_slice=add_df['2018-01-04':]['Adj Close']\n",
    "#df_slice\n"
   ]
  },
  {
   "source": [
    "## Data Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "zip_df=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\ZIP-COUNTY-FIPS_2017-06.csv')\n",
    "cspds_df=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\CSPDSv1.csv')\n",
    "zip_df.rename({'STCOUNTYFP': 'GEO_ID'}, axis=1, inplace=True)\n",
    "zip_df[\"GEO_ID\"] = zip_df[\"GEO_ID\"].astype(str)\n",
    "#print(zip_df.head())\n",
    "\n",
    "\n",
    "#df1=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\Zip_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "#df1['Bedrooms'] = '1'\n",
    "#df1_melt = pd.melt(df1, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName', 'Bedrooms'], var_name='Date', value_name='price_index')\n",
    "\n",
    "#df2=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\Zip_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "#df2['Bedrooms'] = '2'\n",
    "#df2_melt = pd.melt(df2, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName', 'Bedrooms'], var_name='Date', value_name='price_index')\n",
    "\n",
    "df3=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\Zip_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "df3['Bedrooms'] = '3'\n",
    "df3_melt = pd.melt(df3, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName', 'Bedrooms'], var_name='Date', value_name='price_index')\n",
    "\n",
    "#df4=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\Zip_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "#df4['Bedrooms'] = '4'\n",
    "#df4_melt = pd.melt(df4, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName', 'Bedrooms'], var_name='Date', value_name='price_index')\n",
    "\n",
    "#df5=pd.read_csv(r'C:\\Users\\mattl\\Documents\\UVa - Data Science Masters\\CS 5010\\CS-5010-semester-project\\data\\Zip_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "#df5['Bedrooms'] = '5'\n",
    "#df5_melt = pd.melt(df5, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName', 'Bedrooms'], var_name='Date', value_name='price_index')\n",
    "\n",
    "\n",
    "#df = pd.concat([df1_melt, df2_melt, df3_melt, df4_melt, df5_melt], axis=0)\n",
    "#df.rename({'RegionName': 'ZIP'}, axis=1, inplace=True)\n",
    "#df = pd.concat([df1_melt, df2_melt, df3_melt, df4_melt, df5_melt], axis=0)\n",
    "df3_melt.rename({'RegionName': 'ZIP'}, axis=1, inplace=True)\n",
    "#del df1,df2,df3,df4,df5,df1_melt,df2_melt,df3_melt,df4_melt,df5_melt\n",
    "del df3\n",
    "\n",
    "df_merge=df3_melt.merge(zip_df, how='left')\n",
    "df_merge=df_merge.merge(cspds_df, how='left')\n",
    "df_merge['Date']=pd.to_datetime(df_merge['Date'])\n",
    "df_merge=df_merge.set_index('Date').resample('M').mean() #foundational to time series\n",
    "del df3_melt\n",
    "\n",
    "final_df = df_merge.merge(fred_df, left_index=True, right_index=True)\n",
    "#final_df, zip_df, cspds_df\n",
    "\n",
    "#2010 subset\n",
    "df_2012=final_df[datetime(2012, 1, 1):]\n",
    "del final_df\n",
    "\n",
    "df_sub=df_2012[(df_2012['CountyName']=='New York County')]\n",
    "del df_2012\n",
    "\n",
    "#df_sub=df_sub.index.groupby(df_2010['price_index']).mean()\n",
    "\n",
    "df_pp=df_sub[['price_index','CPI','M2','EFFR','10YR','Adj Close','Bedrooms']]\n",
    "del df_sub\n",
    "\n",
    "df_pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_pp, hue=\"Bedrooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sub=df_2015[(df_2015['Metro']=='New York-Newark-Jersey City')]\n",
    "\n",
    "df_pp=df_sub[['price_index','CPI','M2','EFFR','10YR','Adj Close','Bedrooms']]\n",
    "df_pp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Subset data and create pairplot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#df_sub=df_2015[(df_2015['Metro']=='New York-Newark-Jersey City')]\n",
    "\n",
    "\n",
    "#df_pp=df_sub[['price_index','CPI','M2','EFFR','10YR','Adj Close','Bedrooms']]\n",
    "\n",
    "\n",
    "sns.pairplot(df_pp, hue=\"Bedrooms\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Single merge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "############INITIALIZE DF\n",
    "#read zip data\n",
    "zip_df=pd.read_csv(r'data\\ZIP-COUNTY-FIPS_2017-06.csv')\n",
    "zip_df.rename({'STCOUNTYFP': 'GEO_ID'}, axis=1, inplace=True)\n",
    "zip_df[\"GEO_ID\"] = zip_df[\"GEO_ID\"].astype(str)\n",
    "\n",
    "#read bedroom data and melt\n",
    "df1=pd.read_csv(r'data\\Zip_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "df1['Bedrooms'] = '1'\n",
    "df1 = pd.melt(df1, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName', 'Bedrooms'], var_name='Date', value_name='price_index')#.set_index('Date')\n",
    "df1.rename({'RegionName': 'ZIP'}, axis=1, inplace=True)\n",
    "df1['Date']=pd.to_datetime(df1['Date'])\n",
    "\n",
    "#merge zip data\n",
    "df1=df1.merge(zip_df, how='left')\n",
    "df1=df1.set_index('Date')\n",
    "\n",
    "#merge FRED dataset\n",
    "df1 = df1.merge(fred_df, left_index=True, right_index=True)\n",
    "\n",
    "#unique names for list\n",
    "county_list=df1['CountyName'].unique()\n",
    "state_list=df1['State'].unique()\n",
    "\n",
    "\n",
    "############PAIRPLOT FUNCTION\n",
    "#time slice\n",
    "start_date = pd.to_datetime('1/1/2016')\n",
    "end_date = pd.to_datetime('1/1/2020')\n",
    "df1=df1[start_date:end_date]\n",
    "#filter down to Bedroom##############\n",
    "df1=df1[(df1['CountyName']==\"Cook County\") & (df1['State']==\"IL\")].groupby(['CountyName','State','Bedrooms'])['price_index','CASE-SHILLER','CPI','M2','EFFR','30YR_MORT','PERS_SAV','10YR','Adj Close','WTI_OIL','BUSLOANS','CORP_BOND'].resample('M').mean().dropna()\n",
    "\n",
    "\n",
    "#df1.to_csv('df1.csv')\n",
    "df1\n",
    "df1=df1.reset_index(level=2, drop=True)\n",
    "df1=df1.reset_index(level=1, drop=True)\n",
    "df1=df1.reset_index(level=0, drop=True)\n",
    "#df1.columns = df1.columns.map(''.join)\n",
    "#df1.columns = df1.columns.droplevel(1)\n",
    "#x_time=df1.xs('price_index', axis=1, level=0).to_list()\n",
    "\n",
    "\n",
    "#pd.to_datetime(df['EventTime']).dt.date.unique().tolist()\n",
    "df1['price_index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#print(df1)\n",
    "df1=df1.reset_index(level=0, drop=True)\n",
    "#df1.columns = df1.columns.map(''.join)\n",
    "#df1.columns = df1.columns.droplevel(1)\n",
    "#x_time=df1.xs('price_index', axis=1, level=0).to_list()\n",
    "\n",
    "\n",
    "#pd.to_datetime(df['EventTime']).dt.date.unique().tolist()\n",
    "df1['price_index']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(df1.corr(), fignum=f.number)\n",
    "plt.xticks(range(df1.select_dtypes(['number']).shape[1]), df1.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df1.select_dtypes(['number']).shape[1]), df1.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to list\n",
    "county=df1_melt['CountyName'].unique().to_list()\n",
    "print(county)\n",
    "\n",
    "#unique names for list\n",
    "#county=df1['CountyName'].unique()\n",
    "\n",
    "#2010 subset\n",
    "#df_2015=final_df[datetime(2010, 1, 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}